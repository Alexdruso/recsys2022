{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Recsys_VAE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j1Zc9cJ5sPBB",
    "outputId": "8e5f9b13-82ef-4eda-d2c0-75c425af9fae"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_probability as tfp\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[0;32mIn [15]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcolab\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m drive\n\u001B[1;32m      2\u001B[0m drive\u001B[38;5;241m.\u001B[39mmount(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/gdrive\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      3\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39mrun_line_magic(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcd\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/gdrive\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "%cd /gdrive"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Change base path based on GDrive or local run\n",
    "base_path = \"../dataset\"\n",
    "# base_path = \"/gdrive/MyDrive/dressipi_recsys2022_mapped/dataset\"\n",
    "\n",
    "original_data = os.path.join(base_path, 'original_data')\n",
    "processed_data = os.path.join(base_path, 'processed_data')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Prepare dataset"
   ],
   "metadata": {
    "id": "N4VfhKeUsWxY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "tfpl = tfp.layers"
   ],
   "metadata": {
    "id": "owDtEs6MsTc9"
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "items_features = pd.read_csv(os.path.join(processed_data, \"simplified_features.csv\"))\n",
    "items_features.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "1JyKbD7LtKP-",
    "outputId": "4464887d-fdc2-4da4-c40b-f19ab76f0645"
   },
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "   item_id  feature_idx\n0    19021            1\n1    19021           23\n2    19021           16\n3    19021          447\n4    19021            2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>item_id</th>\n      <th>feature_idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>19021</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>19021</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19021</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>19021</td>\n      <td>447</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>19021</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = np.zeros(\n",
    "    (items_features['item_id'].max()+1, items_features['feature_idx'].max()+1)\n",
    "    )\n",
    "dataset[(items_features['item_id'], items_features['feature_idx'])] = 1\n",
    "\n",
    "dataset"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NhWZfcj7z3T4",
    "outputId": "aa304d51-0826-40de-f5c6-514afd328e7c"
   },
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 1., 1., ..., 0., 0., 0.],\n       [0., 1., 1., ..., 0., 0., 0.],\n       ...,\n       [0., 1., 1., ..., 0., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.]])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#VAE"
   ],
   "metadata": {
    "id": "HJzIzAFy198k"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_prior(num_modes, latent_dimension):\n",
    "    \"\"\"\n",
    "    This function should create an instance of a MixtureSameFamily distribution \n",
    "    according to the above specification. \n",
    "    The function takes the num_modes and latent_dim as arguments, which should \n",
    "    be used to define the distribution.\n",
    "    Your function should then return the distribution instance.\n",
    "    \"\"\"\n",
    "    return tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=[1/num_modes for _ in range(num_modes)]),\n",
    "        components_distribution=tfd.MultivariateNormalDiag(\n",
    "            loc=tf.Variable(tf.random.normal(shape=(num_modes, latent_dimension))),\n",
    "            scale_diag=tfp.util.TransformedVariable(\n",
    "                initial_value=tf.ones(\n",
    "                    shape=(num_modes, latent_dimension)\n",
    "                ),\n",
    "                bijector=tfb.Softplus()\n",
    "            )\n",
    "        )\n",
    "    )"
   ],
   "metadata": {
    "id": "iKPlGc5-3ZLy"
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_kl_regularizer(prior_distribution):\n",
    "    \"\"\"\n",
    "    This function should create an instance of the KLDivergenceRegularizer \n",
    "    according to the above specification. \n",
    "    The function takes the prior_distribution, which should be used to define \n",
    "    the distribution.\n",
    "    Your function should then return the KLDivergenceRegularizer instance.\n",
    "    \"\"\"\n",
    "    return tfpl.KLDivergenceRegularizer(\n",
    "        distribution_b=prior_distribution,\n",
    "        weight=1.0,\n",
    "        test_points_fn=lambda q: q.sample(3),\n",
    "        test_points_reduce_axis=None\n",
    "    )"
   ],
   "metadata": {
    "id": "R8t7w3Au3ZXx"
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "latent_dimension = 128\n",
    "starting_dimension = 2**9\n",
    "prior = get_prior(num_modes=2, latent_dimension=latent_dimension)\n",
    "kl_regularizer = get_kl_regularizer(prior)\n",
    "\n",
    "inputs = layers.Input((items_features['feature_idx'].max()+1,))\n",
    "\n",
    "x = inputs \n",
    "dimension = starting_dimension\n",
    "\n",
    "while(dimension != latent_dimension):\n",
    "  x = layers.Dense(units=dimension, activation='relu')(x)\n",
    "  x = layers.BatchNormalization()(x)\n",
    "\n",
    "  dimension = dimension//2\n",
    "\n",
    "x = layers.Dense(units=tfpl.MultivariateNormalTriL.params_size(latent_dimension))(x)\n",
    "outputs = tfpl.MultivariateNormalTriL(latent_dimension, activity_regularizer=kl_regularizer)(x)\n",
    "\n",
    "encoder = tf.keras.Model(inputs=inputs, outputs=outputs, name='encoder')\n",
    "\n",
    "encoder.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fZKmdQ-v19FR",
    "outputId": "c2d38955-1d38-4209-96b9-49c911f033fe"
   },
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 905)]             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 512)               463872    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 8384)              2154688   \n",
      "                                                                 \n",
      " multivariate_normal_tri_l_1  ((None, 128),            512       \n",
      "  (MultivariateNormalTriL)    (None, 128))                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,753,472\n",
      "Trainable params: 2,751,936\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "max_width = 512\n",
    "ending_dimension = items_features['feature_idx'].max()+1\n",
    "\n",
    "inputs = layers.Input((latent_dimension,))\n",
    "\n",
    "x = inputs \n",
    "dimension = latent_dimension\n",
    "\n",
    "while(dimension <= max_width):\n",
    "  x = layers.Dense(units=dimension, activation='relu')(x)\n",
    "  x = layers.BatchNormalization()(x)\n",
    "\n",
    "  dimension = dimension*2\n",
    "\n",
    "x = layers.Dense(units=tfpl.IndependentBernoulli.params_size(ending_dimension))(x)\n",
    "outputs = tfpl.IndependentBernoulli(ending_dimension)(x)\n",
    "\n",
    "decoder = tf.keras.Model(inputs=inputs, outputs=outputs, name='decoder')\n",
    "\n",
    "decoder.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9NHmRW9S4igJ",
    "outputId": "6e750ece-9a5a-42b6-c6ec-86580715afe1"
   },
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 128)]             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 512)               131584    \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 905)               464265    \n",
      "                                                                 \n",
      " independent_bernoulli_1 (In  ((None, 905),            0         \n",
      " dependentBernoulli)          (None, 905))                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 648,969\n",
      "Trainable params: 647,177\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "vae = tf.keras.Model(inputs=encoder.inputs, outputs=decoder(encoder.outputs), name='vae')\n",
    "vae.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KVZltSQC6P3n",
    "outputId": "8b9cb1ea-d9bf-4aa9-e9d2-390b2ba53c4f"
   },
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vae\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 905)]             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 512)               463872    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 8384)              2154688   \n",
      "                                                                 \n",
      " multivariate_normal_tri_l_1  ((None, 128),            512       \n",
      "  (MultivariateNormalTriL)    (None, 128))                       \n",
      "                                                                 \n",
      " decoder (Functional)        (None, 905)               648969    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,402,441\n",
      "Trainable params: 3,399,113\n",
      "Non-trainable params: 3,328\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "vae.compile(\n",
    "    optimizer='adam', \n",
    "    loss=lambda x_true, x_pred : -tf.reduce_mean(x_pred.log_prob(x_true))\n",
    "    )"
   ],
   "metadata": {
    "id": "SDd6FyYl6nv7"
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Training"
   ],
   "metadata": {
    "id": "YrLisRiO73WY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "vae.fit(\n",
    "    dataset,\n",
    "    dataset, \n",
    "    validation_split=0.2, \n",
    "    epochs=100,\n",
    "    callbacks=[\n",
    "               tf.keras.callbacks.EarlyStopping(\n",
    "                  monitor='val_loss',\n",
    "                  patience=5,\n",
    "                  restore_best_weights=True,\n",
    "              )\n",
    "         ]\n",
    "    )"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k66RodSl71Ya",
    "outputId": "db8f8e34-cb80-4ab3-ee41-4c63fa3fdf2d"
   },
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 18:41:01.564940: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "593/593 [==============================] - ETA: 0s - loss: 124.1309"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 18:41:28.548693: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "593/593 [==============================] - 31s 49ms/step - loss: 124.1309 - val_loss: 50.2728\n",
      "Epoch 2/100\n",
      "593/593 [==============================] - 28s 48ms/step - loss: 39.2607 - val_loss: 41.3635\n",
      "Epoch 3/100\n",
      "593/593 [==============================] - 29s 50ms/step - loss: 32.2972 - val_loss: 37.2438\n",
      "Epoch 4/100\n",
      "593/593 [==============================] - 29s 50ms/step - loss: 28.4832 - val_loss: 34.8455\n",
      "Epoch 5/100\n",
      "593/593 [==============================] - 29s 49ms/step - loss: 25.8748 - val_loss: 32.4137\n",
      "Epoch 6/100\n",
      "593/593 [==============================] - 29s 48ms/step - loss: 24.3166 - val_loss: 31.6039\n",
      "Epoch 7/100\n",
      "593/593 [==============================] - 29s 49ms/step - loss: 23.2171 - val_loss: 30.7962\n",
      "Epoch 8/100\n",
      "593/593 [==============================] - 29s 49ms/step - loss: 22.3839 - val_loss: 30.4323\n",
      "Epoch 9/100\n",
      "593/593 [==============================] - 29s 49ms/step - loss: 21.6482 - val_loss: 29.8156\n",
      "Epoch 10/100\n",
      "593/593 [==============================] - 29s 49ms/step - loss: 20.8792 - val_loss: 29.9913\n",
      "Epoch 11/100\n",
      "593/593 [==============================] - 29s 48ms/step - loss: 20.3778 - val_loss: 29.6939\n",
      "Epoch 12/100\n",
      "593/593 [==============================] - 29s 49ms/step - loss: 19.7771 - val_loss: 29.1439\n",
      "Epoch 13/100\n",
      "593/593 [==============================] - 29s 48ms/step - loss: 19.2730 - val_loss: 28.7347\n",
      "Epoch 14/100\n",
      "593/593 [==============================] - 29s 49ms/step - loss: 18.7884 - val_loss: 28.7731\n",
      "Epoch 15/100\n",
      "593/593 [==============================] - 29s 50ms/step - loss: 18.4183 - val_loss: 28.7452\n",
      "Epoch 16/100\n",
      "593/593 [==============================] - 29s 49ms/step - loss: 18.2764 - val_loss: 28.1447\n",
      "Epoch 17/100\n",
      "593/593 [==============================] - 28s 47ms/step - loss: 17.7230 - val_loss: 28.3445\n",
      "Epoch 18/100\n",
      "593/593 [==============================] - 28s 47ms/step - loss: 17.5443 - val_loss: 28.2004\n",
      "Epoch 19/100\n",
      "593/593 [==============================] - 28s 47ms/step - loss: 17.2940 - val_loss: 28.4536\n",
      "Epoch 20/100\n",
      "593/593 [==============================] - 28s 47ms/step - loss: 17.0168 - val_loss: 28.5069\n",
      "Epoch 21/100\n",
      "593/593 [==============================] - 28s 47ms/step - loss: 16.8281 - val_loss: 28.7993\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x2dfa20e50>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "np.save(os.path.join(processed_data, \"compressed_features\"), encoder(dataset).mean())"
   ],
   "metadata": {
    "id": "yb0eE4AX8YsR"
   },
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    ""
   ],
   "metadata": {
    "id": "Tg3gvuN8mpzC"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}